---
layout: post
title: 人工智能-手写识别学习
---

## pytorch 普通实现

---

- 依赖库安装

```python
pip install numpy torch torchvision matplotlib
```

### 完整代码

---

```python
import torch
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import MNIST
import matplotlib.pyplot as plt


class Net(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.fc1 = torch.nn.Linear(28*28, 64)
        self.fc2 = torch.nn.Linear(64, 64)
        self.fc3 = torch.nn.Linear(64, 64)
        self.fc4 = torch.nn.Linear(64, 10)

    def forward(self, x):
        x = torch.nn.functional.relu(self.fc1(x))
        x = torch.nn.functional.relu(self.fc2(x))
        x = torch.nn.functional.relu(self.fc3(x))
        x = torch.nn.functional.log_softmax(self.fc4(x), dim=1)
        return x


def get_data_loader(is_train):
    to_tensor = transforms.Compose([transforms.ToTensor()])
    data_set = MNIST("", is_train, transform=to_tensor, download=True)
    # 一个批次包括15张图片
    return DataLoader(data_set, batch_size=15, shuffle=True)


def evaluate(test_data, net):
    n_correct = 0
    n_total = 0
    with torch.no_grad():
        for (x, y) in test_data:
            outputs = net.forward(x.view(-1, 28*28))
            for i, output in enumerate(outputs):
                if torch.argmax(output) == y[i]:
                    n_correct += 1
                n_total += 1
    return n_correct / n_total


def main():

    train_data = get_data_loader(is_train=True)
    test_data = get_data_loader(is_train=False)
    net = Net() # 初始化神经网络

    print("initial accuracy:", evaluate(test_data, net))
    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)
    # epoch是训练该数据集的轮次，提高数据集的利用率
    for epoch in range(2):
        for (x, y) in train_data:
            net.zero_grad()
            output = net.forward(x.view(-1, 28*28))
            loss = torch.nn.functional.nll_loss(output, y)
            loss.backward()
            optimizer.step()
        print("epoch", epoch, "accuracy:", evaluate(test_data, net))

    for (n, (x, _)) in enumerate(test_data):
        if n > 3:
            break
        predict = torch.argmax(net.forward(x[0].view(-1, 28*28)))
        plt.figure(n)
        plt.imshow(x[0].view(28, 28))
        plt.title("prediction: " + str(int(predict)))
    plt.show()


if __name__ == "__main__":
    main()
```

## 卷积神经网络实现

---

- 墙裂推荐：[从“卷积”、到“图像卷积操作”、再到“卷积神经网络”，“卷积”意义的 3 次改变](https://www.bilibili.com/video/BV1VV411478E/?spm_id_from=333.337.search-card.all.click&vd_source=519c4464a364b8611b8a226be3cda0f6)

```python
import torch # 用于张量计算和自动求导
import torch.nn as nn # 提供神经网络模块（卷积、全连接层等等）
import torch.optim as optim # 包含优化器模块，用于梯度下降的权重更新
import torchvision # 提供计算机视觉县骨干的数据集、模型和图像处理
from torchvision import datasets, transforms # datasets数据集、transforms对数据进行预处理
from torch.utils.data import DataLoader # 用于按批次加载数据
from torch.utils.data import Subset # 从数据集中提取子集

# 检查设备是否可用cuda，否则使用CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 超参数
batch_size = 100 # 每次迭代处理的样本数量，一批
learning_rate = 0.001 # 控制每次权重更新的步长
epochs = 2 # 训练完整数据集轮数

# 数据预处理
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))  # 将数据归一化到 [-1, 1]
])

# 下载 MNIST 数据集
train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)

# 提取数据集子集
# 创建一个包含前 55,000 条数据的子集
subset_indices = list(range(55000))  # 前 55,000 条数据的索引
train_subset = Subset(train_dataset, subset_indices)

# 数据加载器
train_loader = DataLoader(dataset=train_subset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

# 定义 CNN 模型
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.conv1(x))  # 第一层卷积 + 激活
        x = self.pool(x)             # 第一层池化
        x = self.relu(self.conv2(x)) # 第二层卷积 + 激活
        x = self.pool(x)             # 第二层池化
        x = x.view(x.size(0), -1)    # 展平
        x = self.relu(self.fc1(x))   # 全连接层 + 激活
        x = self.fc2(x)              # 输出层
        return x

# 实例化模型
model = CNN().to(device)

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# 训练模型
def train(model, train_loader, criterion, optimizer, device):
    model.train() # 切换到训练模式
    total_batches = len(train_loader)  # 计算每个 epoch 的总批次数
    for epoch in range(epochs):
        total_loss = 0
        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)

            # 前向传播
            outputs = model(images)
            loss = criterion(outputs, labels)

            # 反向传播和优化
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
             # 每 50 批次输出一次训练误差
            if (batch_idx + 1) % 50 == 0:
                print(f"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{total_batches}], Loss: {loss.item():.4f}")


        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(train_loader):.4f}")

# 测试模型
def test(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print(f"Test Accuracy: {100 * correct / total:.2f}%")

# 运行训练和测试
train(model, train_loader, criterion, optimizer, device)
test(model, test_loader, device)
```
