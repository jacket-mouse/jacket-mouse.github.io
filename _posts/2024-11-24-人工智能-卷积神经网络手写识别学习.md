---
layout: post
title: äººå·¥æ™ºèƒ½-æ‰‹å†™è¯†åˆ«å­¦ä¹ 
---

## pytorch ä¼ ç»Ÿç½‘ç»œå®ç°

---

- ä¾èµ–åº“å®‰è£…

```python
pip install numpy torch torchvision matplotlib
```

### å®Œæ•´ä»£ç 

---

```python
import torch
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import MNIST
import matplotlib.pyplot as plt


class Net(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.fc1 = torch.nn.Linear(28*28, 64)
        self.fc2 = torch.nn.Linear(64, 64)
        self.fc3 = torch.nn.Linear(64, 64)
        self.fc4 = torch.nn.Linear(64, 10)

    def forward(self, x):
        x = torch.nn.functional.relu(self.fc1(x))
        x = torch.nn.functional.relu(self.fc2(x))
        x = torch.nn.functional.relu(self.fc3(x))
        x = torch.nn.functional.log_softmax(self.fc4(x), dim=1)
        return x


def get_data_loader(is_train):
    to_tensor = transforms.Compose([transforms.ToTensor()])
    data_set = MNIST("", is_train, transform=to_tensor, download=True)
    # ä¸€ä¸ªæ‰¹æ¬¡åŒ…æ‹¬15å¼ å›¾ç‰‡
    return DataLoader(data_set, batch_size=15, shuffle=True)


def evaluate(test_data, net):
    n_correct = 0
    n_total = 0
    with torch.no_grad():
        for (x, y) in test_data:
            outputs = net.forward(x.view(-1, 28*28))
            for i, output in enumerate(outputs):
                if torch.argmax(output) == y[i]:
                    n_correct += 1
                n_total += 1
    return n_correct / n_total


def main():

    train_data = get_data_loader(is_train=True)
    test_data = get_data_loader(is_train=False)
    net = Net() # åˆå§‹åŒ–ç¥ç»ç½‘ç»œ

    print("initial accuracy:", evaluate(test_data, net))
    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)
    # epochæ˜¯è®­ç»ƒè¯¥æ•°æ®é›†çš„è½®æ¬¡ï¼Œæé«˜æ•°æ®é›†çš„åˆ©ç”¨ç‡
    for epoch in range(2):
        for (x, y) in train_data:
            net.zero_grad()
            output = net.forward(x.view(-1, 28*28))
            loss = torch.nn.functional.nll_loss(output, y)
            loss.backward()
            optimizer.step()
        print("epoch", epoch, "accuracy:", evaluate(test_data, net))

    for (n, (x, _)) in enumerate(test_data):
        if n > 3:
            break
        predict = torch.argmax(net.forward(x[0].view(-1, 28*28)))
        plt.figure(n)
        plt.imshow(x[0].view(28, 28))
        plt.title("prediction: " + str(int(predict)))
    plt.show()


if __name__ == "__main__":
    main()
```

## pytorch å·ç§¯ç¥ç»ç½‘ç»œå®ç°

---

```python
import torch # ç”¨äºå¼ é‡è®¡ç®—å’Œè‡ªåŠ¨æ±‚å¯¼
import torch.nn as nn # æä¾›ç¥ç»ç½‘ç»œæ¨¡å—ï¼ˆå·ç§¯ã€å…¨è¿æ¥å±‚ç­‰ç­‰ï¼‰
import torch.optim as optim # åŒ…å«ä¼˜åŒ–å™¨æ¨¡å—ï¼Œç”¨äºæ¢¯åº¦ä¸‹é™çš„æƒé‡æ›´æ–°
import torchvision # æä¾›è®¡ç®—æœºè§†è§‰ç›¸å…³çš„æ•°æ®é›†ã€æ¨¡å‹å’Œå›¾åƒå¤„ç†
from torchvision import datasets, transforms # datasetsæ•°æ®é›†ã€transformså¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†
from torch.utils.data import DataLoader # ç”¨äºæŒ‰æ‰¹æ¬¡åŠ è½½æ•°æ®
from torch.utils.data import Subset # ä»æ•°æ®é›†ä¸­æå–å­é›†

# æ£€æŸ¥è®¾å¤‡æ˜¯å¦å¯ç”¨cudaï¼Œå¦åˆ™ä½¿ç”¨CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# è¶…å‚æ•°
batch_size = 100 # æ¯æ¬¡è¿­ä»£å¤„ç†çš„æ ·æœ¬æ•°é‡ï¼Œä¸€æ‰¹
learning_rate = 0.001 # æ§åˆ¶æ¯æ¬¡æƒé‡æ›´æ–°çš„æ­¥é•¿
epochs = 2 # è®­ç»ƒå®Œæ•´æ•°æ®é›†è½®æ•°

# æ•°æ®é¢„å¤„ç†
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))  # å°†æ•°æ®å½’ä¸€åŒ–åˆ° [-1, 1]
])

# ä¸‹è½½ MNIST æ•°æ®é›†
train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)

# æå–æ•°æ®é›†å­é›†
# åˆ›å»ºä¸€ä¸ªåŒ…å«å‰ 55,000 æ¡æ•°æ®çš„å­é›†
subset_indices = list(range(55000))  # å‰ 55,000 æ¡æ•°æ®çš„ç´¢å¼•
train_subset = Subset(train_dataset, subset_indices)

# æ•°æ®åŠ è½½å™¨
train_loader = DataLoader(dataset=train_subset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

# å®šä¹‰ CNN æ¨¡å‹
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.conv1(x))  # ç¬¬ä¸€å±‚å·ç§¯ + æ¿€æ´»
        x = self.pool(x)             # ç¬¬ä¸€å±‚æ± åŒ–
        x = self.relu(self.conv2(x)) # ç¬¬äºŒå±‚å·ç§¯ + æ¿€æ´»
        x = self.pool(x)             # ç¬¬äºŒå±‚æ± åŒ–
        x = x.view(x.size(0), -1)    # å±•å¹³
        x = self.relu(self.fc1(x))   # å…¨è¿æ¥å±‚ + æ¿€æ´»
        x = self.fc2(x)              # è¾“å‡ºå±‚
        return x

# å®ä¾‹åŒ–æ¨¡å‹
model = CNN().to(device)

# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# è®­ç»ƒæ¨¡å‹
def train(model, train_loader, criterion, optimizer, device):
    model.train() # åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼
    total_batches = len(train_loader)  # è®¡ç®—æ¯ä¸ª epoch çš„æ€»æ‰¹æ¬¡æ•°
    for epoch in range(epochs):
        total_loss = 0
        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)

            # å‰å‘ä¼ æ’­
            outputs = model(images)
            loss = criterion(outputs, labels)

            # åå‘ä¼ æ’­å’Œä¼˜åŒ–
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
             # æ¯ 50 æ‰¹æ¬¡è¾“å‡ºä¸€æ¬¡è®­ç»ƒè¯¯å·®
            if (batch_idx + 1) % 50 == 0:
                print(f"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{total_batches}], Loss: {loss.item():.4f}")


        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(train_loader):.4f}")

# æµ‹è¯•æ¨¡å‹
def test(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print(f"Test Accuracy: {100 * correct / total:.2f}%")

# è¿è¡Œè®­ç»ƒå’Œæµ‹è¯•
train(model, train_loader, criterion, optimizer, device)
test(model, test_loader, device)
```

## å·ç§¯ç¥ç»ç½‘ç»œå­¦ä¹ 

---

- å¢™è£‚æ¨èï¼š[ä»â€œå·ç§¯â€ã€åˆ°â€œå›¾åƒå·ç§¯æ“ä½œâ€ã€å†åˆ°â€œå·ç§¯ç¥ç»ç½‘ç»œâ€ï¼Œâ€œå·ç§¯â€æ„ä¹‰çš„ 3 æ¬¡æ”¹å˜](https://www.bilibili.com/video/BV1VV411478E/?spm_id_from=333.337.search-card.all.click&vd_source=519c4464a364b8611b8a226be3cda0f6)

  ä¸ä»…æ•™ç»™æˆ‘ä»¬å·ç§¯çš„çŸ¥è¯†ï¼Œè¿˜æ•™ç»™æˆ‘ä»¬ä¸€ç§æ€è€ƒæ–¹å¼ ğŸ¤”ï¼Œä»ç†è®ºçš„å±‚é¢åˆ†æäº†å·ç§¯ã€‚

- [æµ™å¤§å¤§ä½¬æ•™ä½ æ€ä¹ˆå· CNNï¼Œå·ç§¯ç¥ç»ç½‘ç»œ CNN ä»å…¥é—¨åˆ°å®æˆ˜](https://www.bilibili.com/video/BV1zF411V7xu/?spm_id_from=333.337.search-card.all.click&vd_source=519c4464a364b8611b8a226be3cda0f6)

  ç³»åˆ—è¯¾ç¨‹ã€åŒ…æ‹¬ä»£ç å®ç°

- è¾“å…¥å±‚
- å·ç§¯å±‚ï¼šæå–ç‰¹å¾
- æ± åŒ–å±‚å‹ç¼©ç‰¹å¾
- å…¨è¿æ¥å±‚ï¼šåŠ æƒé‡

### å·ç§¯å±‚

---

å·ç§¯ç¥ç»ç½‘ç»œè¿˜æ˜¯ä¸€ä¸ªå­¦ä¹ æ‰¾æœ€ä¼˜æƒé‡å‚æ•°çš„è¿‡ç¨‹ã€‚

å°†å›¾åƒåˆ†æˆå¾ˆå¤šå°åŒºåŸŸï¼Œå¯¹äºæ•´ä¸ªåŸå§‹è¾“å…¥å›¾åƒæŒ‰ç…§ä¸€ä¸ªåŒºåŸŸè¿›è¡ŒåŠ æƒå¾—åˆ°ç‰¹å¾å›¾ï¼Œæ¯ä¸ªç‰¹å¾å›¾çš„æ¯ä¸ªå…ƒç´ æ˜¯ç›¸åº”ä½ç½®å·ç§¯çš„ç»“æœ 32 \* 32 \* 3ï¼Œå…¶ä¸­ 3 è¡¨ç¤º RGB ä¸‰ä¸ªé¢œè‰²é€šé“ï¼Œå¤šé€šé“åˆ†åˆ«å·ç§¯å¾—åˆ°è¾“å‡ºå†ç›¸åŠ ã€‚

åˆ©ç”¨ filter æƒé‡å‚æ•°è¿›è¡Œç‰¹å¾æå–ï¼Œé€šè¿‡ç‰¹å¾å‚æ•°å·ç§¯å’Œå¾—åˆ°ä¸€ä¸ªå€¼ï¼ˆç‰¹å¾å€¼ï¼‰ï¼Œfilter å‰ä¸¤ä¸ªå€¼å¤§å°è¡¨ç¤ºåœ¨åŸå§‹å›¾åƒæ•°æ®ä¸­æ¯å¤šå¤§çš„åŒºåŸŸå¯¹åº”ä¸€ä¸ªç‰¹å¾å€¼ã€‚ä¸åŒé¢œè‰²é€šé“å¯¹åº”çš„ filter é‡Œçš„å€¼è¦ä¸ä¸€æ ·ï¼Œä½†å½¢çŠ¶å’Œå¤§å°åº”è¯¥ä¸€æ ·ã€‚
åˆ©ç”¨å†…ç§¯ï¼ˆå¯¹åº”ä½ç½®ç›¸ä¹˜ï¼‰è¿›è¡Œè®¡ç®—ï¼Œæ³¨æ„åŠ ä¸Šä¸€ä¸ªåç½®é¡¹ Bias b0ã€‚

é€‰æ‹©ä¸åŒç‰¹å¾çŸ©é˜µï¼ˆè§„æ ¼ç›¸åŒï¼‰å¾—åˆ°çš„ç‰¹å¾å›¾ä¸åŒï¼Œæ¯ä¸€æ¬¡å·ç§¯é€‰æ‹©çš„å’Œæ˜¯ä¸€è‡´çš„ï¼Œè¿™æ ·å°±å¯¼è‡´ç»“æœæœ‰å¤šä¸ªï¼Œç§°ä½œä¸ºç‰¹å¾å›¾çš„æ·±åº¦ï¼Œä¸ç”¨ç›¸åŠ è€Œæ˜¯å åœ¨ä¸€èµ·å½¢æˆæ·±åº¦è¿™ä¸€ç»´åº¦ã€‚

æ•´ä¸ªå·ç§¯å±‚ç‰¹å¾æå–è¿‡ç¨‹ï¼šå°†è¾“å…¥å›¾åƒåˆ†éš”æˆå¾ˆå¤šä¸ªåƒç´ ç‚¹ä»¥åŠ RGB ä¸‰ä¸ªé¢œè‰²é€šé“ï¼ˆä¾‹å¦‚ 32 \* 32 \* 3ï¼Œåˆ†éš”æˆé•¿ä¸º 32 å®½ä¸º 32ï¼ŒRGB ä¸‰ä¸ªé¢œè‰²é€šé“ï¼‰ï¼Œé€‰æ‹© fliter ä»¥åŠç§»åŠ¨è·ç¦»ï¼ˆæ­¥é•¿ï¼‰è¿›è¡Œç›¸åº”ä½ç½®å·ç§¯åŠ æƒï¼Œå°†ä¸‰ä¸ªè®¡ç®—ç»“æœä»¥åŠåç½®åŠ èµ·æ¥å¯ä»¥å¾—åˆ°ç‰¹å¾å›¾ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œé‡å¤å¯ä»¥å¾—åˆ°æ•´ä¸ªç‰¹å¾å›¾ï¼›æ”¹å˜åˆå§‹æƒé‡å€¼å¯ä»¥å¾—åˆ°ä¸åŒçš„ç‰¹å¾å›¾ï¼Œç§°ä¸ºæ·±åº¦ã€‚

å·ç§¯å±‚æ¶‰åŠå‚æ•°

- æ»‘åŠ¨çª—å£æ­¥é•¿ï¼šèƒ½ç§»åŠ¨è¶Šå¤šå¾—åˆ°çš„ç‰¹å¾å›¾è¶Šå¤§ï¼Œæå–çš„ç‰¹å¾è¶Šç»†è…»ï¼Œå¸¸è§æ­¥é•¿ä¸º 1
- å·ç§¯æ ¸å°ºå¯¸ï¼šé€‰æ‹©åŒºåŸŸçš„å¤§å°â€”æœ€åå¾—åˆ°ç»“æœä¸ªæ•°çš„å¤§å°ï¼Œä¸€èˆ¬ 3Ã—3
- è¾¹ç¼˜å¡«å……ï¼šç”±äºæ­¥é•¿é€‰æ‹©ï¼Œæœ‰äº›å…ƒç´ é‡å¤åŠ æƒè´¡çŒ®çš„ï¼Œè¶Šå¾€é‡Œçš„ç‚¹è´¡çŒ®å¤šï¼Œè¶Šå¾€å¤–çš„ç‚¹è´¡çŒ®å°‘ï¼Œæ˜¯è¾¹ç•Œç‚¹è´¡çŒ®å¤šäº›ï¼Œåœ¨å¤–é¢åŠ ä¸Šä¸€åœˆ 0ï¼Œå¯ä»¥å¼¥è¡¥ä¸€äº›è¾¹ç•Œç‰¹å¾ç¼ºå¤±ã€‚zero padding ä»¥ 0 ä¸ºå€¼è¿›è¡Œè¾¹ç¼˜å¡«å……
- å·ç§¯æ ¸ä¸ªæ•°ï¼šæœ€åè¦å¾—åˆ°å¤šå°‘ä¸ªç‰¹å¾å›¾ï¼ˆæ¯ä¸ªå·ç§¯å’Œéƒ½æ˜¯ä¸ä¸€æ ·çš„ï¼‰

å®é™…è®¡ç®—å…¬å¼

![](https://1ees0n.oss-cn-qingdao.aliyuncs.com/Github/20241126163216.png)

- H1: è¾“å…¥å±‚é•¿åº¦
- FH: å·ç§¯æ ¸é•¿åº¦
- P: å¡«å……å¤šå°‘å±‚ 0
- S: æ­¥é•¿

- å·ç§¯å‚æ•°å…±äº«ï¼šç”¨åŒæ ·ä¸€ç»„å·ç§¯å’Œå¯¹å›¾åƒä¸­æ¯ä¸€ä¸ªåŒºåŸŸè¿›è¡Œç‰¹å¾æå–

### æ± åŒ–å±‚

---

ç‰¹å¾å¤ªå¤šäº†ï¼Œä½†å¹¶ä¸æ˜¯éƒ½æ˜¯æœ‰ç”¨çš„ï¼Œå› æ­¤è¦è¿›è¡Œå‹ç¼©ï¼ˆä¸‹é‡‡æ ·ï¼‰ï¼Œé€‰æ‹©é‡è¦çš„ç•™ä¸‹äº†ï¼Œä¸é‡è¦çš„ä¸¢å¼ƒï¼Œåªä¼šå¯¹ç‰¹å¾å›¾é•¿å’Œå®½è¿›è¡Œç¼©å‡ï¼Œä¸ä¼šæ”¹å˜ç‰¹å¾å›¾çš„æ·±åº¦ï¼Œæ²¡æœ‰æ¶‰åŠåˆ°çŸ©é˜µçš„è®¡ç®—ã€‚

æ± åŒ–å±‚å‹ç¼©è¿‡ç¨‹ï¼šåœ¨é€šè¿‡å·ç§¯å±‚åå¯¹ç‰¹å¾å›¾è¿›è¡Œç­›é€‰ï¼Œæ»‘åŠ¨çª—å£(ä¾‹å¦‚ï¼šmax pooling å°†è¯¥åŒºåŸŸæœ€å¤§å€¼æå–å‡ºæ¥)

æ•´ä¸ªå·ç§¯ç¥ç»ç½‘ç»œçš„æ¡†æ¶

æ¯æ¬¡å·ç§¯ç»“æŸåéœ€è¦åŠ ä¸Šä¸€ä¸ªéçº¿æ€§å˜æ¢ï¼ˆæ ¸ bp ç¥ç»ç½‘ç»œä¸€è‡´ï¼‰ï¼Œæ‰§è¡Œå‡ æ¬¡å·ç§¯å¾—åˆ°ä¸€ä¸ªæ¯”è¾ƒå¤§çš„ç‰¹å¾å›¾å°±è¿›è¡Œä¸€æ¬¡æ± åŒ–ï¼Œæœ€åçš„ç»“æœè¦è½¬åŒ–ä¸ºåˆ†ç±»çš„æ¦‚ç‡å€¼ï¼ˆå…¨è¿æ¥å±‚ï¼‰

ç”±äºå…¨è¿æ¥å±‚å‚æ•°ä¸èƒ½ä¸º 3 ç»´ï¼Œéœ€è¦æŠŠå¤„ç†è¿‡åçš„ç‰¹å¾å›¾æ‹‰æˆä¸€ä¸ªç‰¹å¾å‘é‡ï¼Œå°†è¯¥å‘é‡è½¬åŒ–ä¸º 5 åˆ†ç±»çš„æ¦‚ç‡å€¼ã€‚

å¸¦å‚æ•°è®¡ç®—æ‰èƒ½ç§°ä½œå±‚ï¼ˆå·ç§¯å±‚å’Œå…¨è¿æ¥å±‚ï¼‰

VGG ç½‘ç»œ

å·ç§¯å¤§å°éƒ½æ˜¯ 3\*3ï¼Œç»è¿‡æ± åŒ–å±‚åä¼šæŸå¤±ä¸€éƒ¨åˆ†ä¿¡æ¯ï¼Œåœ¨ä¸‹ä¸€æ¬¡å·ç§¯è¿‡ç¨‹ä¸­ä½¿å¾—ç‰¹å¾å€¼ç¿»å€ï¼ˆç”¨ç‰¹å¾å›¾çš„ä¸ªæ•°æ¥å¼¥è¡¥é•¿å®½çš„æŸå¤±ï¼‰

Resnet æ®‹å·®ç½‘ç»œ

å¹¶ä¸æ˜¯å±‚æ•°è¶Šå¤šè¶Šå¥½ï¼Œåœ¨å †å å±‚æ•°æ—¶å¯èƒ½æœ‰ä¸å¥½çš„è¿›è¡Œå½±å“ï¼Œéœ€è¦è®¾è®¡ä¸€ä¸ªæ–¹æ¡ˆè¿›è¡Œå‰”é™¤

å¯ä»¥ç†è§£ä¸ºç»è¿‡å·ç§¯å±‚åå­¦çš„ä¸å¥½æŠŠåŸæ¥å­¦çš„å¥½çš„è¦†ç›–äº†ï¼Œç°åœ¨é‡æ–°æ„å»ºå †å åŸå§‹å­¦çš„å¥½çš„é‚£éƒ¨åˆ†ï¼ŒåŠæ—¶ä¹‹å‰ä¸å¥½çš„éƒ¨åˆ†æœ‰å½±å“ï¼Œä½†åªè¦å­¦ä¹ ä½¿å¾—è¯¥éƒ¨åˆ†æƒå€¼ä¸º 0 å³å¯ï¼ˆå¥½çš„æˆ‘ç”¨ï¼Œä¸å¥½çš„æˆ‘æƒé‡ä¸º 0ï¼Œç›¸å½“äºç™½æï¼Œä¹Ÿå°±æ˜¯å¯¹æˆ‘æœ‰ç”¨çš„æˆ‘åŠ ä¸Šï¼Œæ²¡ç”¨çš„æˆ‘ä¹ŸåŠ ä¸Šä½†æ˜¯ä¸å½±å“ï¼Œæœ€åæ•ˆæœè‡³å°‘ä¸€å®šä¸ä¼šæ¯”åŸæ¥å·®ï¼‰

æ„Ÿå—é‡

å½“å‰è¿™ä¸ªå€¼æ˜¯ç”±å‰é¢å¤šå°‘ä¸ªå€¼å‚ä¸è®¡ç®—å¾—åˆ°çš„ï¼Œä¸€èˆ¬å¸Œæœ›æ„Ÿå—é‡è¶Šå¤§è¶Šå¥½ã€‚

3 ä¸ª 3\*3 å·ç§¯å±‚éœ€è¦çš„å‚æ•°æ¯”ä¸€ä¸ªå¤§çš„è¦å‚æ•°å°ï¼Œå®é™…æ•ˆç‡æ›´å¿«ä¸€äº›

è®¡ç®—é€Ÿåº¦ä¸å‚æ•°ä¸ªæ•°æŒ‚é’©ï¼Œå·ç§¯è¶Šå¤šè¶Šç»†è…»ï¼ŒåŠ å…¥çš„éçº¿æ€§å˜æ¢é‡éšç€å¢å¤š
